{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running this pipeline we need to set two important parameters:\n",
    "- s3_input_path: location of the data to be used for inferencing\n",
    "- model_arn: arn of the model to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import sagemaker.session\n",
    "from datetime import datetime\n",
    "from sagemaker import (\n",
    "    image_uris,\n",
    "    model_uris,\n",
    "    script_uris,\n",
    "    hyperparameters,\n",
    "    get_execution_role,\n",
    ")\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.workflow.steps import CacheConfig\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    "    ParameterBoolean,\n",
    ")\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.workflow.steps import (\n",
    "    ProcessingStep,\n",
    "    TuningStep,\n",
    "    TransformStep,\n",
    "    CreateModelStep,\n",
    ")\n",
    "from sagemaker.workflow.step_collections import RegisterModel, EstimatorTransformer\n",
    "from sagemaker.workflow.parameters import ParameterString\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor, ScriptProcessor\n",
    "from sagemaker.predictor import csv_serializer\n",
    "from sagemaker.debugger import rule_configs, Rule, DebuggerHookConfig\n",
    "from sagemaker.model_monitor import (\n",
    "    DataCaptureConfig,\n",
    "    DatasetFormat,\n",
    "    DefaultModelMonitor,\n",
    ")\n",
    "from sagemaker.s3 import S3Uploader, S3Downloader\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "from sagemaker.workflow.functions import Join\n",
    "from sagemaker.model import Model, ModelPackage\n",
    "from sagemaker.inputs import TrainingInput, TransformInput, BatchDataCaptureConfig\n",
    "from sagemaker.transformer import Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket = ParameterString(\n",
    "    \"s3_bucket\", default_value=\"s3://sagemaker-eu-west-1-708699854342\"\n",
    ")\n",
    "s3_project_path = ParameterString(\n",
    "    \"s3_project_path\", default_value=\"knnights/test/shapeshifter\"\n",
    ")\n",
    "\n",
    "model_location = ParameterString(\n",
    "    \"model_location\",\n",
    "    default_value=\"s3://sagemaker-eu-west-1-708699854342/shapeshifter/models/lightgbm/zz4f6n0k2v79-LightGB-oJZZOAXMXV-001-2a98dea5/output/model.tar.gz\",\n",
    ")\n",
    "s3_input_data = ParameterString(\n",
    "    \"s3_input_data\",\n",
    "    default_value=\"s3://nike--708699854342--test--eu-west-1/knnights/test/shapeshifter/inference/data_pipeline\",\n",
    ")\n",
    "encoders_path = ParameterString(\n",
    "    \"encoders_path\",\n",
    "    default_value=\"s3://sagemaker-eu-west-1-708699854342/shapeshifter/data/processed/2023-01-10T07:47:47.735Z/encoders/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "default_bucket = s3_bucket\n",
    "\n",
    "pipeline_session = PipelineSession()\n",
    "\n",
    "cache_config = CacheConfig(enable_caching=False, expire_after=\"1d\")\n",
    "\n",
    "# S3 paths\n",
    "project = \"shapeshifter\"\n",
    "model_type = \"lightgbm\"\n",
    "\n",
    "project_path = Join(values=[\"s3:/\", default_bucket, s3_project_path], on=\"/\")\n",
    "\n",
    "inference_path = Join(values=[project_path, \"inference\"], on=\"/\")\n",
    "inference_live_path = Join(values=[inference_path, \"live\"], on=\"/\")\n",
    "inference_input_path = Join(values=[inference_path, \"input\"], on=\"/\")\n",
    "data_capture = Join(values=[project_path, \"data_capture\"], on=\"/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=\"1.0-1\",\n",
    "    role=role,\n",
    "    instance_type=\"ml.m5.2xlarge\",\n",
    "    instance_count=1,\n",
    "    sagemaker_session=pipeline_session,\n",
    ")\n",
    "\n",
    "root = \"/opt/ml/processing\"\n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name=\"ShapeshifterPrepInferenceData\",\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=s3_input_data, destination=Join(values=[root, \"/input/data\"])\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=encoders_path, destination=Join(values=[root, \"/input/encoders\"])\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"inference_data\",\n",
    "            source=f\"{root}/output\",\n",
    "            destination=inference_input_path,\n",
    "        ),\n",
    "    ],\n",
    "    code=\"inference_processing.py\",\n",
    "    cache_config=cache_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Input data </strong>\n",
    "\n",
    "Make sure to use live data instead of test data in the final inference pipeline!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create a model package\n",
    "# lgbm_model = ModelPackage(\n",
    "#     role=role,\n",
    "#     model_package_arn=boto_client.list_model_packages(\n",
    "#         ModelPackageGroupName=f\"{project}-{model_type}\",\n",
    "#         ModelApprovalStatus=\"Approved\"\n",
    "#     )[\"ModelPackageSummaryList\"][0][\"ModelPackageArn\"],\n",
    "#     source_dir=\"model_scripts\",\n",
    "#     entry_point=\"inference.py\",\n",
    "#     sagemaker_session=pipeline_session,\n",
    "# )\n",
    "\n",
    "docker_image_inference = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,\n",
    "    model_id=f\"{model_type}-regression-model\",\n",
    "    model_version=\"*\",\n",
    "    image_scope=\"inference\",\n",
    "    instance_type=\"ml.m5.large\",\n",
    ")\n",
    "\n",
    "lgbm_model = Model(\n",
    "    model_data=model_location,\n",
    "    image_uri=docker_image_inference,\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "step_create_best_lightgbm = ModelStep(\n",
    "    name=\"GetBestLightGBM\",\n",
    "    step_args=lgbm_model.create(instance_type=\"ml.m5.large\"),\n",
    ")\n",
    "\n",
    "lightgbm_transformer = Transformer(\n",
    "    model_name=step_create_best_lightgbm.properties.ModelName,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    instance_count=1,\n",
    "    output_path=inference_live_path,\n",
    "    sagemaker_session=pipeline_session,\n",
    "    assemble_with=\"Line\",\n",
    "    accept=\"text/csv\",\n",
    "    strategy=\"MultiRecord\",\n",
    "    max_payload=2,\n",
    ")\n",
    "\n",
    "step_lightgbm_transform = TransformStep(\n",
    "    name=\"LightGBMTransform\",\n",
    "    transformer=lightgbm_transformer,\n",
    "    inputs=TransformInput(\n",
    "        step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "            \"inference_data\"\n",
    "        ].S3Output.S3Uri,\n",
    "        content_type=\"text/csv\",\n",
    "        split_type=\"Line\",\n",
    "        batch_data_capture_config=BatchDataCaptureConfig(\n",
    "            destination_s3_uri=data_capture,\n",
    "            generate_inference_id=True,\n",
    "        ),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_name = f\"ShapeshifterPipeline-Inference\"\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    steps=[step_process, step_create_best_lightgbm, step_lightgbm_transform],\n",
    "    parameters=[\n",
    "        s3_bucket,\n",
    "        s3_project_path,\n",
    "        s3_input_data,\n",
    "        encoders_path,\n",
    "        #         model_arn,\n",
    "        model_location,\n",
    "    ],\n",
    ")\n",
    "\n",
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution = pipeline.start(execution_display_name=f\"{project}-{round(time.time())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 29 2022, 11:24:10) \n[Clang 14.0.0 (clang-1400.0.29.102)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aa67735b10bc4be519ace89624978d0cb52c7e3831cd619656f5c60e76fb141d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
