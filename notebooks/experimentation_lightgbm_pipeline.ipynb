{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> LightGBM Only </strong>\n",
    "\n",
    "This notebook can be used for LightGBM models only\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.27.24 requires botocore==1.29.24, but you have botocore 1.29.51 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U sagemaker --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import boto3\n",
    "import sagemaker.session\n",
    "from datetime import datetime\n",
    "from sagemaker import (\n",
    "    image_uris,\n",
    "    model_uris,\n",
    "    script_uris,\n",
    "    hyperparameters,\n",
    "    get_execution_role,\n",
    ")\n",
    "\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.workflow.steps import CacheConfig\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    "    ParameterBoolean,\n",
    "    ParameterFloat,\n",
    ")\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.workflow.steps import (\n",
    "    ProcessingStep,\n",
    "    TuningStep,\n",
    "    TransformStep,\n",
    "    CreateModelStep,\n",
    ")\n",
    "from sagemaker.workflow.step_collections import RegisterModel, EstimatorTransformer\n",
    "from sagemaker.workflow.functions import Join\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "from sagemaker.workflow.lambda_step import LambdaStep\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor, ScriptProcessor\n",
    "from sagemaker.predictor import csv_serializer\n",
    "from sagemaker.debugger import rule_configs, Rule, DebuggerHookConfig\n",
    "from sagemaker.model_monitor import (\n",
    "    DataCaptureConfig,\n",
    "    DatasetFormat,\n",
    "    DefaultModelMonitor,\n",
    ")\n",
    "from sagemaker.s3 import S3Uploader, S3Downloader\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.inputs import TrainingInput, TransformInput\n",
    "from sagemaker.transformer import Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket = ParameterString(\n",
    "    \"s3_bucket\", default_value=\"s3://sagemaker-eu-west-1-708699854342\"\n",
    ")\n",
    "s3_project_path = ParameterString(\n",
    "    \"s3_project_path\", default_value=\"knnights/test/shapeshifter\"\n",
    ")\n",
    "\n",
    "accuracy_mae_threshold = ParameterFloat(name=\"AccuracyMaeThreshold\", default_value=0.5)\n",
    "\n",
    "train_instance_count = ParameterInteger(name=\"TrainInstanceCount\", default_value=1)\n",
    "max_tuning_jobs = ParameterInteger(name=\"MaxTuningJob\", default_value=1)\n",
    "max_parallel_jobs = ParameterInteger(name=\"MaxParallelJobs\", default_value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "default_bucket = s3_bucket\n",
    "\n",
    "pipeline_session = PipelineSession()\n",
    "\n",
    "cache_config = CacheConfig(enable_caching=True, expire_after=\"1d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## s3 Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.execution_variables.ExecutionVariables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 paths\n",
    "project = \"shapeshifter\"\n",
    "model_type = \"lightgbm\"\n",
    "\n",
    "project_path = Join(values=[\"s3:/\", default_bucket, s3_project_path], on=\"/\")\n",
    "data_path = Join(values=[project_path, \"data\"], on=\"/\")\n",
    "output_path = Join(\n",
    "    values=[data_path, \"output\", ExecutionVariables.START_DATETIME], on=\"/\"\n",
    ")\n",
    "model_path = Join(values=[project_path, \"models\"], on=\"/\")\n",
    "input_data_path = Join(values=[data_path, \"input\"], on=\"/\")\n",
    "inference_path = Join(\n",
    "    values=[project_path, \"inference\", ExecutionVariables.START_DATETIME], on=\"/\"\n",
    ")\n",
    "inference_test_path = Join(values=[inference_path, \"test_predictions\"], on=\"/\")\n",
    "\n",
    "data_capture_path = Join(values=[project_path, \"data_capture\"], on=\"/\")\n",
    "\n",
    "data_processed_path = Join(\n",
    "    values=[data_path, \"processed\", ExecutionVariables.START_DATETIME], on=\"/\"\n",
    ")\n",
    "# model_evaluation_path = name_from_base(Join(values=[model_path, \"lightgbm\", \"evaluation\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=\"1.0-1\",\n",
    "    role=role,\n",
    "    instance_type=\"ml.m5.2xlarge\",\n",
    "    instance_count=1,\n",
    "    sagemaker_session=pipeline_session,\n",
    ")\n",
    "\n",
    "root = \"/opt/ml/processing\"\n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name=\"ShapeshifterPrepData\",\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(source=input_data_path, destination=f\"{root}/input\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"train\",\n",
    "            source=f\"{root}/processed/train\",\n",
    "            destination=Join(values=[data_processed_path, \"train\"], on=\"/\"),\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"validation\",\n",
    "            source=f\"{root}/processed/validation\",\n",
    "            destination=Join(values=[data_processed_path, \"validation\"], on=\"/\"),\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"test\",\n",
    "            source=f\"{root}/processed/test\",\n",
    "            destination=Join(values=[data_processed_path, \"test\"], on=\"/\"),\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"test_with_header\",\n",
    "            source=f\"{root}/processed/test_with_header\",\n",
    "            destination=Join(values=[data_processed_path, \"with_header\"], on=\"/\"),\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"test_no_target\",\n",
    "            source=f\"{root}/processed/test_no_target\",\n",
    "            destination=Join(values=[data_processed_path, \"test_no_target\"], on=\"/\"),\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=model_type,\n",
    "            source=f\"{root}/processed/{model_type}\",\n",
    "            destination=Join(values=[data_processed_path, \"lightgbm\"], on=\"/\"),\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"encoders\",\n",
    "            source=f\"{root}/processed/encoders\",\n",
    "            destination=Join(values=[data_processed_path, \"encoders\"], on=\"/\"),\n",
    "        ),\n",
    "    ],\n",
    "    code=\"processing.py\",\n",
    "    cache_config=cache_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type = \"ml.m5.2xlarge\"\n",
    "objective_metric_name = \"rmse\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Why can't we use the train_source_uri?? </strong>\n",
    "\n",
    "s3://jumpstart-cache-prod-eu-west-1/source-directory-tarballs/lightgbm/inference/regression/v1.1.2/ is not accessible?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy: s3://jumpstart-cache-prod-eu-west-1/source-directory-tarballs/lightgbm/inference/regression/v1.1.2/sourcedir.tar.gz to s3://sagemaker-eu-west-1-708699854342/shapeshifter/lightgbm/model_scripts/sourcedir.tar.gz\n"
     ]
    }
   ],
   "source": [
    "! aws s3 cp s3://jumpstart-cache-prod-eu-west-1/source-directory-tarballs/lightgbm/inference/regression/v1.1.2/ s3://sagemaker-eu-west-1-708699854342/shapeshifter/lightgbm/model_scripts/ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:258: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_model_id, train_model_version = f\"{model_type}-regression-model\", \"*\"\n",
    "docker_image_train = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,\n",
    "    model_id=train_model_id,\n",
    "    model_version=train_model_version,\n",
    "    image_scope=\"training\",\n",
    "    instance_type=instance_type,\n",
    ")\n",
    "\n",
    "train_source_uri = script_uris.retrieve(\n",
    "    model_id=train_model_id, model_version=train_model_version, script_scope=\"training\"\n",
    ")\n",
    "\n",
    "train_model_uri = model_uris.retrieve(\n",
    "    model_id=train_model_id, model_version=train_model_version, model_scope=\"training\"\n",
    ")\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"learning_rate\": ContinuousParameter(1e-4, 1, scaling_type=\"Logarithmic\"),\n",
    "    \"num_boost_round\": IntegerParameter(10, 100),\n",
    "    #     \"early_stoppings\": IntegerParameter(2, 20),\n",
    "    \"num_leaves\": IntegerParameter(10, 30),\n",
    "    \"feature_fraction\": ContinuousParameter(0, 1),\n",
    "    \"bagging_fraction\": ContinuousParameter(0, 1),\n",
    "    \"bagging_freq\": IntegerParameter(1, 10),\n",
    "    \"max_depth\": IntegerParameter(5, 30),\n",
    "    \"min_data_in_leaf\": IntegerParameter(5, 50),\n",
    "    \"tweedie_variance_power\": ContinuousParameter(1, 1.99),\n",
    "    \"boosting\": CategoricalParameter([\"gbdt\", \"dart\"]),\n",
    "}\n",
    "\n",
    "hp = hyperparameters.retrieve_default(\n",
    "    model_id=train_model_id, model_version=train_model_version\n",
    ")\n",
    "\n",
    "lightgbm_estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=docker_image_train,\n",
    "    source_dir=train_source_uri,\n",
    "    model_uri=train_model_uri,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    entry_point=\"transfer_learning.py\",\n",
    "    instance_type=instance_type,\n",
    "    output_path=Join(values=[model_path, model_type], on=\"/\"),\n",
    "    base_job_name=f\"{project}-{model_type}\",\n",
    "    sagemaker_session=pipeline_session,\n",
    "    hyperparameters=hp,\n",
    ")\n",
    "\n",
    "metric_definitions = [\n",
    "    {\"Name\": objective_metric_name, \"Regex\": f\"{objective_metric_name}: ([0-9\\.]+)\"},\n",
    "]\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator=lightgbm_estimator,\n",
    "    objective_metric_name=objective_metric_name,\n",
    "    objective_type=\"Minimize\",\n",
    "    metric_definitions=metric_definitions,\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    max_jobs=max_tuning_jobs,\n",
    "    max_parallel_jobs=max_parallel_jobs,\n",
    ")\n",
    "\n",
    "step_lightgbm_tuning = TuningStep(\n",
    "    name=\"LightGBMHPTuning\",\n",
    "    step_args=tuner.fit(\n",
    "        inputs=TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"lightgbm\"\n",
    "            ].S3Output.S3Uri\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "step_lightgbm_tuning.add_depends_on([step_process])\n",
    "\n",
    "model_type = \"lightgbm\"\n",
    "docker_image_inference = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,\n",
    "    model_id=f\"{model_type}-regression-model\",\n",
    "    model_version=\"*\",\n",
    "    image_scope=\"inference\",\n",
    "    instance_type=instance_type,\n",
    ")\n",
    "\n",
    "best_lightgbm_model = Model(\n",
    "    name=\"shapeshifter-lightgbm\",\n",
    "    image_uri=docker_image_inference,\n",
    "    model_data=step_lightgbm_tuning.get_top_model_s3_uri(\n",
    "        top_k=0,\n",
    "        s3_bucket=sagemaker_session.default_bucket(),\n",
    "        prefix=f\"shapeshifter/models/{model_type}\",\n",
    "    ),\n",
    "    source_dir=\"model_scripts\",\n",
    "    sagemaker_session=pipeline_session,\n",
    "    entry_point=\"inference.py\",\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_create_best_lightgbm = ModelStep(\n",
    "    name=\"CreateBestLightGBM\",\n",
    "    step_args=best_lightgbm_model.create(instance_type=\"ml.m5.xlarge\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create predictionspath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import BatchDataCaptureConfig\n",
    "\n",
    "lightgbm_transformer = Transformer(\n",
    "    model_name=step_create_best_lightgbm.properties.ModelName,\n",
    "    instance_type=\"ml.m5.2xlarge\",\n",
    "    instance_count=1,\n",
    "    output_path=inference_test_path,\n",
    "    sagemaker_session=pipeline_session,\n",
    "    assemble_with=\"Line\",\n",
    "    accept=\"text/csv\",\n",
    "    strategy=\"MultiRecord\",\n",
    "    max_payload=2,\n",
    ")\n",
    "\n",
    "step_lightgbm_transform = TransformStep(\n",
    "    name=\"LightGBMTransform\",\n",
    "    transformer=lightgbm_transformer,\n",
    "    inputs=TransformInput(\n",
    "        step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "            \"test_no_target\"\n",
    "        ].S3Output.S3Uri,\n",
    "        content_type=\"text/csv\",\n",
    "        split_type=\"Line\",\n",
    "        batch_data_capture_config=BatchDataCaptureConfig(\n",
    "            destination_s3_uri=data_capture_path,\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "\n",
    "step_lightgbm_transform.add_depends_on([step_create_best_lightgbm])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_evaluation_processor = SKLearnProcessor(\n",
    "    framework_version=\"1.0-1\",\n",
    "    role=role,\n",
    "    instance_type=\"ml.m5.4xlarge\",\n",
    "    instance_count=1,\n",
    ")\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\", output_name=\"evaluation\", path=\"evaluation.json\"\n",
    ")\n",
    "\n",
    "step_evaluate_lightgbm = ProcessingStep(\n",
    "    name=\"EvaluateModelLightGBM\",\n",
    "    processor=sklearn_evaluation_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"test\"\n",
    "            ].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/input\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=inference_test_path,\n",
    "            destination=f\"/opt/ml/processing/input/{model_type}\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"evaluation\",\n",
    "            source=\"/opt/ml/processing/evaluation\",\n",
    "            destination=Join(values=[inference_test_path, \"evaluation\"], on=\"/\"),\n",
    "        ),\n",
    "    ],\n",
    "    code=\"evaluate.py\",\n",
    "    property_files=[evaluation_report],\n",
    ")\n",
    "\n",
    "step_evaluate_lightgbm.add_depends_on([step_lightgbm_transform])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker import clarify\n",
    "\n",
    "# shap_config = clarify.SHAPConfig(\n",
    "#     baseline=[test_features.iloc[0].values.tolist()],\n",
    "#     num_samples=15,\n",
    "#     agg_method=\"mean_abs\",\n",
    "#     save_local_shap_values=True,\n",
    "# )\n",
    "\n",
    "# explainability_output_path = \"s3://{}/{}/clarify-explainability\".format(bucket, prefix)\n",
    "# explainability_data_config = clarify.DataConfig(\n",
    "#     s3_data_input_path=train_uri,\n",
    "#     s3_output_path=explainability_output_path,\n",
    "#     label=\"Target\",\n",
    "#     headers=training_data.columns.to_list(),\n",
    "#     dataset_type=\"text/csv\",\n",
    "# )\n",
    "# clarify_processor.run_explainability(\n",
    "#     data_config=explainability_data_config,\n",
    "#     model_config=model_config,\n",
    "#     explainability_config=shap_config,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ModelMetrics object using the evaluation report from the evaluation step\n",
    "# A ModelMetrics object contains metrics captured from a model.\n",
    "model_metrics_lightgbm = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=Join(\n",
    "            values=[\n",
    "                step_evaluate_lightgbm.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][\n",
    "                    0\n",
    "                ][\"S3Output\"][\"S3Uri\"],\n",
    "                \"evaluation.json\",\n",
    "            ],\n",
    "            on=\"/\",\n",
    "        ),\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create a RegisterModel step, which registers the model with Sagemaker Model Registry.\n",
    "step_register_lightgbm_model = RegisterModel(\n",
    "    name=\"RegisterLightgbm\",\n",
    "    estimator=lightgbm_estimator,\n",
    "    model_data=step_create_best_lightgbm.properties.PrimaryContainer.ModelDataUrl,\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.m5.large\"],\n",
    "    transform_instances=[\"ml.m5.large\"],\n",
    "    model_package_group_name=f\"{project}-{model_type}\",\n",
    "    approval_status=\"PendingManualApproval\",\n",
    "    model_metrics=model_metrics_lightgbm,\n",
    "    description=\"Model for Shapeshifter predictions based on LightGBM\",\n",
    "    depends_on=[step_evaluate_lightgbm],\n",
    "    image_uri=docker_image_inference,\n",
    ")\n",
    "\n",
    "step_register_lightgbm_model_approval = RegisterModel(\n",
    "    name=\"RegisterLightgbmApproved\",\n",
    "    estimator=lightgbm_estimator,\n",
    "    model_data=step_create_best_lightgbm.properties.PrimaryContainer.ModelDataUrl,\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.m5.large\"],\n",
    "    transform_instances=[\"ml.m5.large\"],\n",
    "    model_package_group_name=f\"{project}-{model_type}\",\n",
    "    approval_status=\"Approved\",\n",
    "    model_metrics=model_metrics_lightgbm,\n",
    "    description=\"Model for Shapeshifter predictions based on LightGBM\",\n",
    "    depends_on=[step_evaluate_lightgbm],\n",
    "    image_uri=docker_image_inference,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.workflow.lambda_step import LambdaStep\n",
    "# from sagemaker.lambda_helper import Lambda\n",
    "\n",
    "# endpoint_config_name = \"shapeshifter-endpoint-config\"\n",
    "# endpoint_name = \"shapeshifter-endpoint\" #Join(values=[\"shapeshifter-endpoint-\", ExecutionVariables.START_DATETIME], on=\"\")\n",
    "\n",
    "# deploy_model_lambda_function_name = \"sagemaker-deploy-model-lambda\" #Join(values=[\"sagemaker-deploy-model-lambda-\", ExecutionVariables.START_DATETIME], on=\"\")\n",
    "\n",
    "# deploy_model_lambda_function = Lambda(\n",
    "#     function_name=deploy_model_lambda_function_name,\n",
    "#     execution_role_arn=role,\n",
    "#     script=\"deploy_model.py\",\n",
    "#     handler=\"deploy_model.lambda_handler\",\n",
    "# )\n",
    "\n",
    "# step_deploy_model_lambda = LambdaStep(\n",
    "#     name=\"DeployShapeshifterModelToEndpoint\",\n",
    "#     lambda_func=deploy_model_lambda_function,\n",
    "#     inputs={\n",
    "#         \"model_name\": step_create_best_lightgbm.properties.ModelName,\n",
    "#         \"endpoint_config_name\": endpoint_config_name,\n",
    "#         \"endpoint_name\": endpoint_name,\n",
    "#         \"endpoint_instance_type\": \"ml.m5.xlarge\",\n",
    "#     },\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_config = ProcessingStep(\n",
    "    name=\"ShapeshifterSaveConfig\",\n",
    "    processor=sklearn_processor,\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            source=\"/opt/ml/processing/config\",\n",
    "            destination=Join(values=[project_path, \"config\"], on=\"/\"),\n",
    "        ),\n",
    "    ],\n",
    "    job_arguments=[\n",
    "        \"--training-date\",\n",
    "        ExecutionVariables.START_DATETIME,\n",
    "        \"--encoders-s3-path\",\n",
    "        step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "            \"encoders\"\n",
    "        ].S3Output.S3Uri,\n",
    "        \"--model-location\",\n",
    "        step_create_best_lightgbm.properties.PrimaryContainer.ModelDataUrl,\n",
    "    ],\n",
    "    code=\"create_config.py\",\n",
    "    cache_config=cache_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy condition step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "\n",
    "# Create accuracy condition to ensure the model meets performance requirements.\n",
    "# Models with a test accuracy lower than the condition will not be registered with the model registry.\n",
    "cond_lte = ConditionLessThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=step_evaluate_lightgbm.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"regression_metrics.mean_absolute_error.value\",\n",
    "    ),\n",
    "    right=accuracy_mae_threshold,\n",
    ")\n",
    "\n",
    "# Create a Sagemaker Pipelines ConditionStep, using the condition above.\n",
    "# Enter the steps to perform if the condition returns True / False.\n",
    "step_cond = ConditionStep(\n",
    "    name=\"MAELowerThanThresholdCondition\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_register_lightgbm_model_approval, step_config],\n",
    "    else_steps=[step_register_lightgbm_model],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:eu-west-1:708699854342:pipeline/shapeshifterpipeline-lightgbm',\n",
       " 'ResponseMetadata': {'RequestId': '3cbe01b8-8f66-4f81-9026-849ad3e82a7d',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '3cbe01b8-8f66-4f81-9026-849ad3e82a7d',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '97',\n",
       "   'date': 'Wed, 18 Jan 2023 15:09:16 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_name = f\"ShapeshifterPipeline-LightGBM\"\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        s3_bucket,\n",
    "        s3_project_path,\n",
    "        accuracy_mae_threshold,\n",
    "        train_instance_count,\n",
    "        max_tuning_jobs,\n",
    "        max_parallel_jobs,\n",
    "    ],\n",
    "    steps=[\n",
    "        step_process,\n",
    "        step_lightgbm_tuning,\n",
    "        step_create_best_lightgbm,\n",
    "        step_lightgbm_transform,\n",
    "        step_evaluate_lightgbm,\n",
    "        step_cond,\n",
    "    ],\n",
    ")\n",
    "\n",
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution = pipeline.start(execution_display_name=f\"{project}-{round(time.time())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "shapeshifter-uGk12AyF-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 29 2022, 11:24:10) \n[Clang 14.0.0 (clang-1400.0.29.102)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "b5d33762232102f988b9fee6a610045f471d96e14f604ae25894a2b2a771ae9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
